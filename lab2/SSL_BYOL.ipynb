{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bootstrap Your Own Latent (BYOL)\n",
        "\n",
        "In this session we are going to implement Bootstrap Your Own Latent paper (https://arxiv.org/abs/2006.07733).\n",
        "\n",
        "It uses a MoCo-style training (with asymmetric SiameseNet) but with a L2 loss penalty (it is not a contrastive-base method)."
      ],
      "metadata": {
        "id": "IIhoHTwntu1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.io import read_image\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "import copy"
      ],
      "metadata": {
        "id": "NVw6H3IEJVuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0Yv5FeDvVm8"
      },
      "outputs": [],
      "source": [
        "# loss fn\n",
        "def loss_fn(x, y): #normalizzo i vettori x e y e ritorno la distanza euclidea\n",
        "    x = F.normalize(x, dim=-1, p=2)\n",
        "    y = F.normalize(y, dim=-1, p=2)\n",
        "    return 2 - 2 * (x * y).sum(dim=-1)\n",
        "\n",
        "\n",
        "class EMA():\n",
        "    # exponential moving average\n",
        "    def __init__(self, beta):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "\n",
        "    def update_average(self, old, new): #prende un parametro della rete target (old) e il corrispettivo della rete online (new)\n",
        "        if old is None:\n",
        "            return new\n",
        "        return old * self.beta + (1 - self.beta) * new\n",
        "\n",
        "def update_moving_average(ema_updater, ma_model, current_model): #prende l'istanza di EMA (attributo della rete target), la rete target e la rete online\n",
        "    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()): #per ogni corrispondente coppia di parametri delle due reti\n",
        "        old_weight, up_weight = ma_params.data, current_params.data\n",
        "        ma_params.data = ema_updater.update_average(old_weight, up_weight) #aggiorna i parametri della rete target\n",
        "\n",
        "# MLP class for projector and predictor\n",
        "\n",
        "def MLP(dim, projection_size, hidden_size=4096, sync_batchnorm=None):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(dim, hidden_size),\n",
        "        nn.BatchNorm1d(hidden_size),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(hidden_size, projection_size)\n",
        "    )\n",
        "\n",
        "\n",
        "class BYOL(nn.Module):\n",
        "    def __init__(self, backbone, moving_average_decay = 0.99):\n",
        "        super().__init__()\n",
        "\n",
        "        self.target_ema_updater = EMA(moving_average_decay)\n",
        "\n",
        "        self.online_net = backbone #l'encoder della rete online è la backbone\n",
        "        self.online_net.fc = nn.Identity() #rimuovo il layer fully connected della rete online\n",
        "        self.online_projector = MLP(512, 512, 4096) #il projector della rete online è un MLP, che alla fine lascia la dimensione a 512\n",
        "\n",
        "    def _get_target_encoder(self):\n",
        "        if self.target_net is None:\n",
        "            target_net = copy.deepcopy(self.online_net) #la rete target viene inizializzata come deep copy della rete online\n",
        "            for p in target_net.parameters():\n",
        "                p.requires_grad = False #disabilito il calcolo del gradiente per ogni peso della rete target, questi infatti si aggiornano tramite EMA\n",
        "            self.target_net = target_net\n",
        "        else:\n",
        "            target_net = self.target_net\n",
        "        return target_net\n",
        "\n",
        "    def update_moving_average(self):\n",
        "        update_moving_average(self.target_ema_updater, self.target_net, self.online_net)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "\n",
        "        images = torch.cat((x1, x2), dim = 0) #concateno i batch delle due viste\n",
        "\n",
        "        # con self.online_net(images) passo le immagini della rete online nella backbone, e il risultato lo passo al projector ottenendo le relative proiezioni\n",
        "        online_projections = self.online_projector(self.online_net(images))\n",
        "\n",
        "\n",
        "        online_pred_one, online_pred_two = online_projections.chunk(2, dim = 0) #le proiezioni le splitto in due tensori, uno per vista\n",
        "\n",
        "        with torch.no_grad():\n",
        "            target_net = self._get_target_encoder()\n",
        "\n",
        "            target_projections = target_net(images) #ottengo le proiezioni delle immagini embedded\n",
        "            target_projections = target_projections.detach()\n",
        "            target_proj_one, target_proj_two = target_projections.chunk(2, dim = 0) #anche qui splitto le proiezioni in due tensori, uno per vista\n",
        "\n",
        "        loss_one = loss_fn(online_pred_one, target_proj_two.detach()) #loss calcolata usando la prima vista nella rete online e la seconda vista nella rete target\n",
        "        loss_two = loss_fn(online_pred_two, target_proj_one.detach()) #loss calcolata usando la seconda vista nella rete online e la prima vista nella rete target\n",
        "\n",
        "        #sommo le due loss e ritorno la media\n",
        "        loss = loss_one + loss_two\n",
        "        return loss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 0\n",
        "\n",
        "Study the above code.\n",
        "- Where is the EMA updates? #dove interviene nel training, cosa e come freezzi il gradiente?\n",
        "- Why it computes both loss_one and loss_two values? -> La loss è simmetrica, è somma di due modi diversi di dare le viste all'encoder. In Sto confrontanfdo le l'uscita della rete online su una trasformazione con l'uscita della rete target su un'altra trasformazione della stessa immagine (simil-positive)"
      ],
      "metadata": {
        "id": "sTq2njrMrvkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vogliamo che le reti imparino l'una dall'altra quindi la loss deve essere effettuata tra view diverse delle 2 reti - calcolo a croce."
      ],
      "metadata": {
        "id": "YHxE4YREl8YY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1\n",
        "\n",
        "Write the training loop for moco-style training as used in BYOL.\n",
        "Use the Dataset which creates the two augmented views for each image and the Siamese Network from the past lab session [1](https://colab.research.google.com/drive/1NJwAFbRiD4MdwWf__6P2Lm0xYk_DNdVu?usp=sharing) and [2](https://colab.research.google.com/drive/1AMkh0q8L5nJScx7v6cMWoK336zqOqDY6?usp=sharing)."
      ],
      "metadata": {
        "id": "m3lt3jwGryO-"
      }
    }
  ]
}