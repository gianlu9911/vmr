{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision.io import read_image\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "7V0_dqyp6Xr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VTKyrCGZznL"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, data, targets, transform=None, target_transform=None):\n",
        "        self.imgs = data\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.imgs[idx]\n",
        "        if isinstance(img, str):\n",
        "          img = read_image(img)\n",
        "        label = self.targets[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "\n",
        "# simclr DA pipeline\n",
        "s=1\n",
        "color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "transform = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
        "                                  transforms.RandomHorizontalFlip(),\n",
        "                                  transforms.RandomApply([color_jitter], p=0.8),\n",
        "                                  transforms.RandomGrayscale(p=0.2),\n",
        "                                  GaussianBlur(kernel_size=int(0.1 * size)),\n",
        "                                  transforms.ToTensor()])\n",
        "\n",
        "# create training set from CustomDataset\n",
        "trainset = ..."
      ],
      "metadata": {
        "id": "60smFlUQZ8jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "VaVLG3S4aCl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")\n",
        "\n",
        "\n",
        "# use this\n",
        "notransform = transforms.Compose([transforms.ToTensor()])\n",
        "non_augmented = torchvision.datasets.CIFAR10(root='./data', train=True, transform=notransform)\n",
        "\n",
        "\n",
        "from torchvision.utils import make_grid\n",
        "imgs = torch.stack((*[non_augmented[i][0] for i in range(10)],\n",
        "                    *[trainset[i][0] for i in range(10)],\n",
        "                    *[trainset[i][1] for i in range(10)]))\n",
        "grid = make_grid(imgs, nrow=10)\n",
        "\n",
        "transforms.ToPILImage()(grid)"
      ],
      "metadata": {
        "id": "WyyTXZspaJF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1\n",
        "Create the custom training set using the cifar10 images and targets"
      ],
      "metadata": {
        "id": "kvXfkKY2bqWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2\n",
        "Modify the custom dataset to return two different views of an input image and create a train loop as the following example"
      ],
      "metadata": {
        "id": "5dh3kdFhb4rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "for idx, data in enumerate(dataloader):\n",
        "    images, targets = data\n",
        "    print(images.shape)\n",
        "    print(targets.shape)\n",
        "    if idx == 3:\n",
        "        break"
      ],
      "metadata": {
        "id": "lHXQazQ2b2lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 3\n",
        "\n",
        "Plot a positive pair and a negative pair of a mini-batch of sample"
      ],
      "metadata": {
        "id": "ER1mDS5BczmD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FW4bfNa-cyy3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}