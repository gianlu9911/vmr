{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JzpkMBzadM9250PhvFmP_EjMyU13syrs","timestamp":1731417651216}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import os\n","import pandas as pd\n","import time\n","\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from torchvision.io import read_image\n","\n","import torchvision\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","\n","from PIL import Image"],"metadata":{"id":"xaJjICcLhd2B","executionInfo":{"status":"ok","timestamp":1734526581924,"user_tz":-60,"elapsed":9565,"user":{"displayName":"Niccolò Menghini","userId":"04046644175323531925"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["Fino ad ora abbiamo definito:\n","- un dataset che restituisce 2 immagini transformed + il suo training loop\n","- una rete siamese (sia simmettrica che asimmetrica)\n","\n","Oggi vedremo come usare una siamese asimmetrica.\n","Una volte estreatte le feature vorremo creare una loss che presi due valori di feature, ci renda un valore di loss.\n","\n","Vogliamo una soluzione base:\n","- niente for loop (optional)\n","- vedremo insieme una versione più complessa"],"metadata":{"id":"pdLEDRJjiR-Z"}},{"cell_type":"code","source":["# Custom Dataset class\n","class CustomImageDataset(Dataset):\n","    def __init__(self, data, targets=None, transform=None, target_transform=None):\n","        self.imgs = data # Tensore di tutte le immagini\n","        self.targets = targets\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.imgs)\n","\n","    def __getitem__(self, idx):\n","        img = self.imgs[idx] # Sampling randomico di emlementi del dataset\n","        if isinstance(img, str): # Può capitare che il dataset sia salvato come stringhe/path (da usare quando non è possibile salvarsi tutto il tensore del dataset)\n","          img = read_image(img_path) # Fuzione di Torchvision, trova un'immaigne dal path fornito\n","        else:\n","          img = Image.fromarray(img.astype('uint8'), 'RGB') # Preso un array restituisce un'immagine RGB, senza non si riesce a lavorare\n","        if self.targets:\n","          label = self.targets[idx] # Non utile nel caso di self-supervised ovviamente\n","        if self.transform:\n","          img1 = self.transform(img) # Utilizzo le trasformazioni\n","          img2 = self.transform(img)  # Già così genero due immagini augmented diverse, siccome le funzioni che trasformano sono randomiche (TODO, rivedi le variabili)\n","        if self.target_transform:\n","          label1 = self.target_transform(label)\n","          label2 = self.target_transform(label)\n","        return img1, img2, label # Concateno immaigni e labels\n","\n","# Simmetric Siamese\n","class SiameseNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.backbone = models.resnet18()\n","        self.backbone.fc = nn.Identity()\n","\n","\n","    def forward(self, x1, x2):\n","        # buona pratica, concatenare x1 e x2 in un unico tensore\n","        x1 = self.backbone(x1)\n","        x2 = self.backbone(x2)\n","        return torch.cat((x1, x2), dim=0) # concatena x1 e x2"],"metadata":{"id":"ifP0qtkSldLI","executionInfo":{"status":"ok","timestamp":1734526581924,"user_tz":-60,"elapsed":9,"user":{"displayName":"Niccolò Menghini","userId":"04046644175323531925"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Contrastive Loss\n","\n","---\n","In this session, we are going to implement the SimCLR loss function (https://arxiv.org/abs/2002.05709).\n","\n","This follows the InfoNCE loss, i.e., uses two different augmented versions of the same image as positive pair and the other images in the batch as negative samples, and the batch construction of the N-pair-mc loss.\n","\n","I negative sono tutti i positive degli altri esempi.\n","\n","Costruisco una matrice in cui metto nella prima posizione di ogni riga il sample di partenza, nella seconda i positive e nelle restanti righe i negative.\n","\n","La cross entropy dovrà avere un'etichetta.\n","\n","Non ho una z di projection, non cambia nulla siccome non addestriamo, però si può inserire."],"metadata":{"id":"9WlzRGSguPAX"}},{"cell_type":"code","source":["torch.cat((torch.Tensor([1, 2, 3]), torch.Tensor([4, 5, 6])), dim=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lm9M1BCWpJWQ","executionInfo":{"status":"ok","timestamp":1734526581925,"user_tz":-60,"elapsed":9,"user":{"displayName":"Niccolò Menghini","userId":"04046644175323531925"}},"outputId":"d4b4ef50-935e-4e23-dad9-04e0505d6cd7"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 2., 3., 4., 5., 6.])"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["class ForContrastiveLoss(nn.Module):\n","    def __init__(self, temperature=0.07):\n","        super().__init__()\n","        self.temperature = temperature\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","\n","    def forward(self, features):\n","        ### features = torch.cat((x1,x2), dim=0)\n","        # normalize features to later compute cosine distance/similarity btw them\n","        features = F.normalize(features, dim=1)\n","        # compute the similarity matrix btw features\n","        # (consider that feature are normalized! so the cosine similarity is ...)\n","        batch_size = len(features)//2\n","        similarity_matrix = torch.matmul(features, features.T)\n","\n","        ## TODO\n","        start = time.time()\n","        # create the logits tensor where:\n","        #   - in the first position there is the similarity of the positive pair\n","        #   - in the other 2N-1 positions there are the similarity w negatives\n","        # the shape of the tensor need to be 2Nx2N-1, with N is the batch size -> 2N-1 negative perché più negative ho meglio funziona l'apprendimento\n","        logits = torch.zeros(2*batch_size, 2*batch_size-1)\n","\n","        for idx, val in enumerate(similarity_matrix):\n","          row = torch.zeros(2*batch_size - 1)\n","\n","          pos_idx = idx + batch_size if idx < batch_size else idx - batch_size\n","          row[0] = val[pos_idx]\n","          row[1:] = torch.tensor([v for i, v in enumerate(val) if  i != idx and i!=pos_idx])\n","\n","          logits[idx] = row\n","\n","        logits = logits / self.temperature\n","\n","        # to compute the contrastive loss using the CE loss, we just need to\n","        # specify where is the similarity of the positive pair in the logits tensor\n","        # since we put in the first position we create a gt of all zeros\n","        # N.B.: this is just one of the possible implementations!\n","        gt = torch.zeros(logits.shape[0], dtype=torch.long)\n","        loss = self.criterion(logits, gt)\n","        end = time.time()\n","        t = end - start\n","        return loss, t"],"metadata":{"id":"sSmQfu5Ve6wi","executionInfo":{"status":"ok","timestamp":1734526581925,"user_tz":-60,"elapsed":7,"user":{"displayName":"Niccolò Menghini","userId":"04046644175323531925"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Se voglio calcolare le tempistiche per bene devo iniziare a prendere il tempo dopo il calcolo della similarity matrix e la fine dopo il calcolo della loss.\n","C'è da rivedere il tutto.\n","\n","Miglioro tutto se faccio operazioni in place in teoria.\n","Altra possibiità di miglioramento è ridurre le maschere a qualcosa di utile per le rappresentazioni sparse.\n","\n","Con queste loss basate su contrasto, la memoria diventa una risorsa cruciale, soprattutto considerando che più negative uso, più funziona bene."],"metadata":{"id":"VCE7a36Ciu_V"}},{"cell_type":"code","source":["class ContrastiveLoss(nn.Module):\n","    def __init__(self, temperature=0.07):\n","        super().__init__()\n","        self.temperature = temperature\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","\n","    def forward(self, features):\n","        ### features = torch.cat((x1,x2), dim=0)\n","        # normalize features to later compute cosine distance/similarity btw them\n","        features = F.normalize(features, dim=1)\n","        # compute the similarity matrix btw features\n","        # (consider that feature are normalized! so the cosine similarity is ...)\n","        batch_size = len(features)//2\n","        similarity_matrix = torch.matmul(features, features.T)\n","\n","        start = time.time()\n","        labels = torch.cat([torch.arange(features.shape[0]//2) for i in range(2)], dim=0)\n","        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float() #simpatico trick\n","        mask = torch.eye(labels.shape[0], dtype=torch.bool) # maschera per togliere la diagonale\n","        labels = labels[~mask].view(labels.shape[0], -1) # Tolgo la diagonale principale sia da labels che dalla similarity matrix\n","        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n","\n","        ## TODO\n","\n","        positives = similarity_matrix[labels.bool()].view(labels.shape[0], -1)\n","        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n","\n","        # create the logits tensor where:\n","        #   - in the first position there is the similarity of the positive pair\n","        #   - in the other 2N-1 positions there are the similarity w negatives\n","        # the shape of the tensor need to be 2Nx2N-1, with N is the batch size -> 2N-1 negative perché più negative ho meglio funziona l'apprendimento\n","\n","        logits = torch.cat([positives, negatives], dim=1)\n","        logits = logits / self.temperature\n","\n","        # to compute the contrastive loss using the CE loss, we just need to\n","        # specify where is the similarity of the positive pair in the logits tensor\n","        # since we put in the first position we create a gt of all zeros\n","        # N.B.: this is just one of the possible implementations!\n","        gt = torch.zeros(logits.shape[0], dtype=torch.long)\n","        loss = self.criterion(logits, gt)\n","        end = time.time()\n","        t = end - start\n","        return loss, t"],"metadata":{"id":"ABbKJPlwuOb0","executionInfo":{"status":"ok","timestamp":1734526581925,"user_tz":-60,"elapsed":6,"user":{"displayName":"Niccolò Menghini","userId":"04046644175323531925"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class NContrastiveLoss(nn.Module):\n","    def __init__(self, temperature=0.07):\n","        super().__init__()\n","        self.temperature = temperature\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","\n","    def forward(self, features):\n","        ### features = torch.cat((x1,x2), dim=0)\n","        # normalize features to later compute cosine distance/similarity btw them\n","        features = F.normalize(features, dim=1)\n","        # compute the similarity matrix btw features\n","        # (consider that feature are normalized! so the cosine similarity is ...)\n","        batch_size = len(features)//2\n","        logits = torch.matmul(features, features.T)\n","\n","        start = time.time()\n","\n","        pos1 = logits.diag(batch_size)\n","        pos2 = logits.diag(-batch_size)\n","        logits = logits[~(torch.cat([torch.arange(features.shape[0]//2) for i in range(2)], dim=0).unsqueeze(0) == torch.cat([torch.arange(features.shape[0]//2) for i in range(2)], dim=0).unsqueeze(1))].view(2*batch_size, -1)\n","        logits = torch.cat((torch.cat((pos1, pos2), dim=0).unsqueeze(1), logits), dim=1)\n","\n","        ## TODO\n","\n","\n","        # create the logits tensor where:\n","        #   - in the first position there is the similarity of the positive pair\n","        #   - in the other 2N-1 positions there are the similarity w negatives\n","        # the shape of the tensor need to be 2Nx2N-1, with N is the batch size -> 2N-1 negative perché più negative ho meglio funziona l'apprendimento\n","\n","        logits = logits / self.temperature\n","\n","        # to compute the contrastive loss using the CE loss, we just need to\n","        # specify where is the similarity of the positive pair in the logits tensor\n","        # since we put in the first position we create a gt of all zeros\n","        # N.B.: this is just one of the possible implementations!\n","        gt = torch.zeros(logits.shape[0], dtype=torch.long)\n","        loss = self.criterion(logits, gt)\n","        end = time.time()\n","        t = end - start\n","        return loss, t"],"metadata":{"id":"7aaCinRxMSM6","executionInfo":{"status":"ok","timestamp":1734526581925,"user_tz":-60,"elapsed":6,"user":{"displayName":"Niccolò Menghini","userId":"04046644175323531925"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Let's now use the Dataset which creates the two augmented views for each image and the Siamese Network from the past lab session [1](https://colab.research.google.com/drive/1NJwAFbRiD4MdwWf__6P2Lm0xYk_DNdVu?usp=sharing) and [2](https://colab.research.google.com/drive/1AMkh0q8L5nJScx7v6cMWoK336zqOqDY6?usp=sharing) and create a training loop"],"metadata":{"id":"Agvz2chP0Ndg"}},{"cell_type":"code","source":["dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n","\n","s=1\n","size=32\n","color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n","transform = transforms.Compose([transforms.RandomResizedCrop(size=size),\n","                                  transforms.RandomHorizontalFlip(),\n","                                  transforms.RandomApply([color_jitter], p=0.8),\n","                                  transforms.RandomGrayscale(p=0.2),\n","                                  transforms.GaussianBlur(kernel_size=3),\n","                                  transforms.ToTensor()])"],"metadata":{"id":"IJQTDd6McEnT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734526589339,"user_tz":-60,"elapsed":7420,"user":{"displayName":"Niccolò Menghini","userId":"04046644175323531925"}},"outputId":"0a3e1da9-f2f6-43e0-b61b-0f093ed3c1a2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:03<00:00, 45.6MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"id":"ow1YmaRPt-Py","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734537005200,"user_tz":-60,"elapsed":1271885,"user":{"displayName":"Niccolò Menghini","userId":"04046644175323531925"}},"outputId":"b586088d-ffe8-4727-a714-246606807c75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Our variant took on average:0.006391294148503517\n"]}],"source":["trainset = CustomImageDataset(dataset.data, dataset.targets, transform=transform)\n","dataloader = DataLoader(trainset, batch_size=256, shuffle=True)\n","\n","model = SiameseNet()\n","optimizer = optim.Adam(model.parameters())\n","criterion = NContrastiveLoss()\n","\n","\n","times = []\n","for idx, data in enumerate(dataloader):\n","    v1, v2, _ = data\n","    v1 = v1\n","    v2 = v2\n","    optimizer.zero_grad()\n","    output = model(v1, v2)\n","    loss, t = criterion(output)\n","    loss.backward()\n","    optimizer.step()\n","    times.append(t)\n","\n","print(f\"Our variant took on average:{np.mean(times)}\")\n","      # if idx == 3:\n","      #     break"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734538269770,"user_tz":-60,"elapsed":1264573,"user":{"displayName":"Niccolò Menghini","userId":"04046644175323531925"}},"outputId":"aaee8967-a0a2-4629-cae5-241cc3947b1f","id":"kEoIRucE1Wid"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mask variant took on average:0.01670169465395869\n"]}],"source":["trainset = CustomImageDataset(dataset.data, dataset.targets, transform=transform)\n","dataloader = DataLoader(trainset, batch_size=256, shuffle=True)\n","\n","model = SiameseNet()\n","optimizer = optim.Adam(model.parameters())\n","criterion = ContrastiveLoss()\n","\n","\n","times = []\n","for idx, data in enumerate(dataloader):\n","    v1, v2, _ = data\n","    v1 = v1\n","    v2 = v2\n","    optimizer.zero_grad()\n","    output = model(v1, v2)\n","    loss, t = criterion(output)\n","    loss.backward()\n","    optimizer.step()\n","    times.append(t)\n","\n","print(f\"Mask variant took on average:{np.mean(times)}\")\n","      # if idx == 3:\n","      #     break"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734539711634,"user_tz":-60,"elapsed":1441869,"user":{"displayName":"Niccolò Menghini","userId":"04046644175323531925"}},"outputId":"026ea774-d58f-46b7-9a79-b8e0e5675316","id":"KyC5NhB61Y8k"},"outputs":[{"output_type":"stream","name":"stdout","text":["For variant took on average:0.797833861136923\n"]}],"source":["trainset = CustomImageDataset(dataset.data, dataset.targets, transform=transform)\n","dataloader = DataLoader(trainset, batch_size=256, shuffle=True)\n","\n","model = SiameseNet()\n","optimizer = optim.Adam(model.parameters())\n","criterion = ForContrastiveLoss()\n","\n","\n","times = []\n","for idx, data in enumerate(dataloader):\n","    v1, v2, _ = data\n","    v1 = v1\n","    v2 = v2\n","    optimizer.zero_grad()\n","    output = model(v1, v2)\n","    loss, t = criterion(output)\n","    loss.backward()\n","    optimizer.step()\n","    times.append(t)\n","\n","print(f\"For variant took on average:{np.mean(times)}\")\n","      # if idx == 3:\n","      #     break"]},{"cell_type":"markdown","source":["Supposed CUDA\n","For:\n","0.053777456283569336\n","0.05588936805725098\n","0.05563950538635254\n","0.05593299865722656\n","\n","mask:\n","0.0048694610595703125\n","0.0016055107116699219\n","0.002445697784423828\n","0.0035674571990966797\n","\n","Supposed CPU\n","For:\n","0.01118779182434082\n","0.012949943542480469\n","0.011744260787963867\n","0.011047601699829102\n","\n","mask:\n","0.0007627010345458984\n","0.0007863044738769531\n","0.0006840229034423828\n","0.0010235309600830078"],"metadata":{"id":"pLC8zkSbKy5d"}},{"cell_type":"markdown","source":["Our variant took on average:\n","0.0008311143616581208 (64)\n","0.00207529958251797 (128)\n","0.006391294148503517 (256)\n","\n","Better variant took on average:\n","0.001560683445552426 (64)\n","0.004945228776663466 (128)\n","0.01670169465395869 (256)\n","\n","For variant took on average:\n","0.04765970017903906 (64)\n","0.2059327104817266 (128)\n","0.797833861136923 (256)"],"metadata":{"id":"pFFudoD-NNov"}},{"cell_type":"markdown","source":["# DOMANDE\n","- Ottimizzazione in place -> velocizza davvero o è solo una questione di memoria\n","- Le due loss servono solo per convergenza più rapida?\n","- Perché con la gpu va un botto (5x) più lento"],"metadata":{"id":"Edp0jE-KMz-U"}},{"cell_type":"code","source":[],"metadata":{"id":"p8vXKvGgNJhP","executionInfo":{"status":"ok","timestamp":1734530794301,"user_tz":-60,"elapsed":7,"user":{"displayName":"Niccolò Menghini","userId":"04046644175323531925"}}},"execution_count":10,"outputs":[]}]}