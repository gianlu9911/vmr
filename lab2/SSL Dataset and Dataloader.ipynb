{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7V0_dqyp6Xr2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1VTKyrCGZznL"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomImageDataset\u001b[39;00m(Dataset):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, targets, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, target_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m data\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None, target_transform=None):\n",
    "        self.imgs = data # equivale a random sampling\n",
    "        self.targets = targets# equivale a random sampling\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = imgs[idx]\n",
    "        if isinstance(img, str):\n",
    "          image = read_image(img_path)# si va per path, se mettessi tutto in RAM non mi ci entrerebbe mai tutto il tensore\n",
    "        label = self.targets[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)# COSì NE HAI SOLO 1 DI COPIE, TE NE SERIVEREBBERO 2, \n",
    "            #                               se hai funzioni randomiche baste che lancia la stessa cosa 2 volte\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta invocate 128 volte, quello che devo fare è concatenare immagini a labels\n",
    "così ho set img e 128 int che sono le etichette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "60smFlUQZ8jb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:12<00:00, 13478052.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# simclr DA pipeline\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m color_jitter \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mColorJitter(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m s, \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m s, \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m s, \u001b[38;5;241m0.2\u001b[39m \u001b[38;5;241m*\u001b[39m s)\n\u001b[0;32m      5\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mRandomResizedCrop(size\u001b[38;5;241m=\u001b[39msize),\n\u001b[0;32m      6\u001b[0m                                   transforms\u001b[38;5;241m.\u001b[39mRandomHorizontalFlip(),\n\u001b[0;32m      7\u001b[0m                                   transforms\u001b[38;5;241m.\u001b[39mRandomApply([color_jitter], p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m),\n\u001b[0;32m      8\u001b[0m                                   transforms\u001b[38;5;241m.\u001b[39mRandomGrayscale(p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m      9\u001b[0m                                   GaussianBlur(kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m size)),\n\u001b[0;32m     10\u001b[0m                                   transforms\u001b[38;5;241m.\u001b[39mToTensor()])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# create training set from CustomDataset\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "\n",
    "# simclr DA pipeline\n",
    "color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "transform = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                  transforms.RandomGrayscale(p=0.2),\n",
    "                                  GaussianBlur(kernel_size=int(0.1 * size)),\n",
    "                                  transforms.ToTensor()])\n",
    "\n",
    "# create training set from CustomDataset\n",
    "trainset = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaVLG3S4aCl_"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WyyTXZspaJF2"
   },
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")\n",
    "\n",
    "\n",
    "# use this\n",
    "notransform = transforms.Compose([transforms.ToTensor()])\n",
    "non_augmented = torchvision.datasets.CIFAR10(root='./data', train=True, transform=notransform)\n",
    "\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "imgs = torch.stack((*[non_augmented[i][0] for i in range(10)],\n",
    "                    *[trainset[i][0] for i in range(10)],\n",
    "                    *[trainset[i][1] for i in range(10)]))\n",
    "grid = make_grid(imgs, nrow=10)\n",
    "\n",
    "transforms.ToPILImage()(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvXfkKY2bqWt"
   },
   "source": [
    "## Exercise 1\n",
    "Create the custom training set using the cifar10 images and targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dh3kdFhb4rP"
   },
   "source": [
    "## Exercise 2\n",
    "Modify the custom dataset to return two different views of an input image and create a train loop as the following example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHXQazQ2b2lh"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "for idx, data in enumerate(dataloader):\n",
    "    images, targets = data\n",
    "    print(images.shape)\n",
    "    print(targets.shape)\n",
    "    if idx == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ER1mDS5BczmD"
   },
   "source": [
    "## Exercise 3\n",
    "\n",
    "Plot a positive pair and a negative pair of a mini-batch of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FW4bfNa-cyy3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPgGShDbD8TzK2rzc2OdxCM",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
