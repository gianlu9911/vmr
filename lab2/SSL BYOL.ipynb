{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIhoHTwntu1V"
   },
   "source": [
    "# Bootstrap Your Own Latent (BYOL)\n",
    "\n",
    "In this session we are going to implement Bootstrap Your Own Latent paper (https://arxiv.org/abs/2006.07733).\n",
    "\n",
    "It uses a MoCo-style training (with asymmetric SiameseNet) but with a L2 loss penalty (it is not a contrastive-base method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "NVw6H3IEJVuk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "# target == teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDatasetBis(Dataset):\n",
    "    def __init__(self, data, targets=None, transform=None, target_transform=None):\n",
    "        self.imgs = data # Tensore di tutte le immagini\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx] # Sampling randomico di emlementi del dataset\n",
    "        if isinstance(img, str): # Può capitare che il dataset sia salvato come stringhe/path (da usare quando non è possibile salvarsi tutto il tensore del dataset)\n",
    "          img = read_image(img_path) # Fuzione di Torchvision, trova un'immaigne dal path fornito\n",
    "        else:\n",
    "          img = Image.fromarray(img.astype('uint8'), 'RGB')\n",
    "        label = self.targets[idx] # Non utile nel caso di self-supervised ovviamente\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img) # Utilizzo le trasformazioni\n",
    "            img2 = self.transform(img)\n",
    "            # img = self.transform(img)  Già così genero due immagini augmented diverse, siccome le funzioni che trasformano sono randomiche (TODO, rivedi le variabili)\n",
    "        if self.target_transform:\n",
    "            label1 = self.target_transform(label)\n",
    "            label2 = self.target_transform(label)\n",
    "        else:\n",
    "            label1 = label\n",
    "            label2 = label\n",
    "        return img1, img2# , label1, label2 # Concateno immaigni e labels\n",
    "    \n",
    "# simclr DA pipeline\n",
    "s=1\n",
    "size=32\n",
    "color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
    "transform = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
    "                                  transforms.RandomHorizontalFlip(),\n",
    "                                  transforms.RandomApply([color_jitter], p=0.8),\n",
    "                                  transforms.RandomGrayscale(p=0.2),\n",
    "                                  transforms.GaussianBlur(kernel_size=3),\n",
    "                                  transforms.ToTensor()])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)   \n",
    "trainset = CustomImageDatasetBis(data.data, data.targets, transform=transform)\n",
    "dataloader = DataLoader(trainset, batch_size=64, shuffle=True, pin_memory=True)# fast computation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "y0Yv5FeDvVm8"
   },
   "outputs": [],
   "source": [
    "#! scrivi come funzioan training loop di byol\n",
    "\n",
    "# loss fn\n",
    "def loss_fn(x, y):# equivalente alla distanza suller slide per byol, equivalente a cosine similarity...\n",
    "    x = F.normalize(x, dim=-1, p=2)\n",
    "    y = F.normalize(y, dim=-1, p=2)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)# proporzionale to cosine similarity\n",
    "\n",
    "\n",
    "class EMA():\n",
    "    # exponential moving average\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new# fa interpolazione alla alpha way\n",
    "\n",
    "def update_moving_average(ema_updater, ma_model, current_model):\n",
    "    for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "        old_weight, up_weight = ma_params.data, current_params.data\n",
    "        ma_params.data = ema_updater.update_average(old_weight, up_weight)\n",
    "\n",
    "# MLP class for projector and predictor\n",
    "\n",
    "def MLP(dim, projection_size, hidden_size=4096, sync_batchnorm=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, hidden_size),\n",
    "        nn.BatchNorm1d(hidden_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(hidden_size, projection_size)\n",
    "    )\n",
    "\n",
    "\n",
    "class BYOL(nn.Module):# siamese net asimmetrica\n",
    "    def __init__(self, backbone, moving_average_decay = 0.99):\n",
    "        super().__init__()\n",
    "        self.target_ema_updater = EMA(moving_average_decay) # update with exponential moving average\n",
    "        self.target_net=None\n",
    "\n",
    "\n",
    "        self.online_net = backbone # update with SGD\n",
    "        self.online_net.fc = nn.Identity()\n",
    "        self.online_projector = MLP(512, 512, 4096)\n",
    "\n",
    "    def _get_target_encoder(self):\n",
    "        if self.target_net is None:\n",
    "            target_net = copy.deepcopy(self.online_net)\n",
    "            for p in target_net.parameters():\n",
    "                p.requires_grad = False\n",
    "            self.target_net = target_net\n",
    "        else:\n",
    "            target_net = self.target_net\n",
    "        return target_net\n",
    "\n",
    "    def update_moving_average(self):\n",
    "        update_moving_average(self.target_ema_updater, self.target_net, self.online_net)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "\n",
    "        images = torch.cat((x1, x2), dim = 0)\n",
    "\n",
    "        online_projections = self.online_projector(self.online_net(images))\n",
    "        online_pred_one, online_pred_two = online_projections.chunk(2, dim = 0)\n",
    "\n",
    "        with torch.no_grad():# \n",
    "            target_net = self._get_target_encoder()\n",
    "\n",
    "            target_projections = target_net(images)\n",
    "            target_projections = target_projections.detach()\n",
    "            target_proj_one, target_proj_two = target_projections.chunk(2, dim = 0)\n",
    "\n",
    "        loss_one = loss_fn(online_pred_one, target_proj_two.detach())# efficienza - èosso calcolare, con le 2 batch aumentate, posso calcolaarlo come 2 batch di dati, la prima volta apsso una vista \n",
    "        # e posso tranquillamente fare il contrario, passo la seconda vista a onlie e la prima la passo al target \n",
    "\n",
    "        # posso calcolarlio come se avessi 2 vatch\n",
    "\n",
    "        # NON POSSO FARLO CON CONTRASTIVE LOSS: perché ogni volta guardo tutti i negative quindi non posso swappare perché sarebbe la stessa cosa\n",
    "        #qui invece ogni istanza è indipendente\n",
    "        loss_two = loss_fn(online_pred_two, target_proj_one.detach())\n",
    "\n",
    "        loss = loss_one + loss_two\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTq2njrMrvkM"
   },
   "source": [
    "## Exercise 0\n",
    "PROB:\n",
    "come fare stiopping gradient: una della 2 reti non ha il gradiente su di esse, c'è qualcos'altro da aggiungere. vedi lato pretrained network quando hai freezato i parameteri\n",
    "\n",
    "come mai calcoli 2 loss?\n",
    "\n",
    "nel report non ci metti ne tabelle ne grafi ma devo fare building block di ogni metodo e implementazione\n",
    "\n",
    "puoi usare grafici fatti a mano che aiutano a spiegare quello che vogliamo dire e.g. power point o canva x accompagnare spiegazione\n",
    "\n",
    "capacità do capire e esporre un metodo\n",
    "\n",
    "\n",
    "# NB: da solo il modello tende a collasse, lo studente evita collapse perché segue rete che non è aggiornato con sgd\n",
    "\n",
    "\n",
    "\n",
    "Study the above code.\n",
    "- Where is the EMA updates? # dove interviene nel training, cosa e come freezzi il gradiente?\n",
    "- Why it computes both loss_one and loss_two values? -> La loss è simmetrica, è somma di due modi diversi di dare le viste all'encoder. In Sto confrontanfdo le l'uscita della rete online su una trasformazione con l'uscita della rete target su un'altra trasformazione della stessa immagine (simil-positive)\n",
    "\n",
    "# vogliamo che le reti imparino l'una dall'altra quindi la loss deve essere effettuata tra view diverse delle 2 reti - calcolo a croce. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3lt3jwGryO-"
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "Write the training loop for moco-style training as used in BYOL.\n",
    "Use the Dataset which creates the two augmented views for each image and the Siamese Network from the past lab session [1](https://colab.research.google.com/drive/1NJwAFbRiD4MdwWf__6P2Lm0xYk_DNdVu?usp=sharing) and [2](https://colab.research.google.com/drive/1AMkh0q8L5nJScx7v6cMWoK336zqOqDY6?usp=sharing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commenti\n",
    "prendo implementazione siamese network in cui ongline upodated with sgd and target EMA\n",
    "# per la predizione prendi quello di online\n",
    "il predittore lo devo scartare per evlautation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice:  0  Loss:  4.095646858215332\n",
      "Indice:  1  Loss:  1.4419841766357422\n",
      "Indice:  2  Loss:  1.4254175424575806\n",
      "Indice:  3  Loss:  1.4239393472671509\n"
     ]
    }
   ],
   "source": [
    "backbone = models.resnet18()\n",
    "model = BYOL(backbone).to('cuda')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "online_projector_param = {'params': model.online_projector.parameters()}\n",
    "online_net_param = {'params': model.online_net.parameters()}\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD([online_net_param, online_projector_param], lr=0.4, momentum =0.9, weight_decay = 1e-04)\n",
    "#2 torch.nograd che agisce su backward\n",
    "#1 requiresgradfalse utile per optimizer step \n",
    "for idx, (x1,x2) in enumerate(dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    x1 = x1.cuda()\n",
    "    x2 = x2.cuda()\n",
    "    loss = model(x1, x2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    model.update_moving_average() # is it enough to update the target net?\n",
    "\n",
    "    print('Indice: ', idx, ' Loss: ', loss.item())\n",
    "\n",
    "    if idx == 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "byol = BYOL(backbone).to('cuda')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOk/QADKe9g1pIFWMcYznPE",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
